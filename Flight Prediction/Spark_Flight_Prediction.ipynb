{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/12 18:23:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Flight Delay Prediction') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "airports_df = (spark.read\n",
    "               .format(\"csv\")\n",
    "               .option('header', 'true')\n",
    "               .load(\"airports.csv\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "DataFrame[summary: string, IATA_CODE: string, AIRPORT: string, CITY: string, STATE: string, COUNTRY: string, LATITUDE: string, LONGITUDE: string]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "airlines_df = (spark.read\n",
    "               .format(\"csv\")\n",
    "               .option('header', 'true')\n",
    "               .load(\"airlines.csv\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[summary: string, IATA_CODE: string, AIRLINE: string]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "flights_df = (spark.read\n",
    "              .format(\"csv\")\n",
    "              .option('header', 'true')\n",
    "              .load(\"flights.csv\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "DataFrame[summary: string, YEAR: string, MONTH: string, DAY: string, DAY_OF_WEEK: string, AIRLINE: string, FLIGHT_NUMBER: string, TAIL_NUMBER: string, ORIGIN_AIRPORT: string, DESTINATION_AIRPORT: string, SCHEDULED_DEPARTURE: string, DEPARTURE_TIME: string, DEPARTURE_DELAY: string, TAXI_OUT: string, WHEELS_OFF: string, SCHEDULED_TIME: string, ELAPSED_TIME: string, AIR_TIME: string, DISTANCE: string, WHEELS_ON: string, TAXI_IN: string, SCHEDULED_ARRIVAL: string, ARRIVAL_TIME: string, ARRIVAL_DELAY: string, DIVERTED: string, CANCELLED: string, CANCELLATION_REASON: string, AIR_SYSTEM_DELAY: string, SECURITY_DELAY: string, AIRLINE_DELAY: string, LATE_AIRCRAFT_DELAY: string, WEATHER_DELAY: string]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "flights_df = flights_df.drop(*['YEAR', 'FLIGHT_NUMBER', 'AIRLINE', 'DISTANCE', 'TAIL_NUMBER', 'TAXI_OUT',\n",
    "                              'SCHEDULED_TIME', 'DEPARTURE_TIME', 'WHEELS_OFF', 'ELAPSED_TIME',\n",
    "                              'AIR_TIME', 'WHEELS_ON', 'DAY_OF_WEEK', 'TAXI_IN', 'CANCELLATION_REASON'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Row(MONTH='1', DAY='1', ORIGIN_AIRPORT='ANC', DESTINATION_AIRPORT='SEA', SCHEDULED_DEPARTURE='0005', DEPARTURE_DELAY='-11', SCHEDULED_ARRIVAL='0430', ARRIVAL_TIME='0408', ARRIVAL_DELAY='-22', DIVERTED='0', CANCELLED='0', AIR_SYSTEM_DELAY=None, SECURITY_DELAY=None, AIRLINE_DELAY=None, LATE_AIRCRAFT_DELAY=None, WEATHER_DELAY=None)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "flights_df = flights_df.withColumn('AIR_SYSTEM_DELAY', flights_df['AIR_SYSTEM_DELAY'].cast('double'))\n",
    "flights_df = flights_df.withColumn('SECURITY_DELAY', flights_df['SECURITY_DELAY'].cast('double'))\n",
    "flights_df = flights_df.withColumn('AIRLINE_DELAY', flights_df['AIRLINE_DELAY'].cast('double'))\n",
    "flights_df = flights_df.withColumn('LATE_AIRCRAFT_DELAY', flights_df['LATE_AIRCRAFT_DELAY'].cast('double'))\n",
    "flights_df = flights_df.withColumn('WEATHER_DELAY', flights_df['WEATHER_DELAY'].cast('double'))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "DataFrame[MONTH: string, DAY: string, ORIGIN_AIRPORT: string, DESTINATION_AIRPORT: string, SCHEDULED_DEPARTURE: string, DEPARTURE_DELAY: string, SCHEDULED_ARRIVAL: string, ARRIVAL_TIME: string, ARRIVAL_DELAY: string, DIVERTED: string, CANCELLED: string, AIR_SYSTEM_DELAY: double, SECURITY_DELAY: double, AIRLINE_DELAY: double, LATE_AIRCRAFT_DELAY: double, WEATHER_DELAY: double]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "\n",
    "def fill_with_mean(df, exclude=set()):\n",
    "    stats = df.agg(*(\n",
    "        avg(c).alias(c) for c in df.columns if c not in exclude\n",
    "    ))\n",
    "    return df.na.fill(stats.first().asDict())\n",
    "\n",
    "fill_with_mean(flights_df, [\"MONTH\", \"DAY\", \"ORIGIN_AIRPORT\", \"DESTINATION_AIRPORT\", \"SCHEDULED_DEPARTURE\", \"SCHEDULED_ARRIVAL\", \"ARRIVAL_TIME\", \"DIVERTED\", \"CANCELLED\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+--------------+-------------------+-------------------+---------------+-----------------+------------+-------------+--------+---------+----------------+--------------+-------------+-------------------+-------------+------+\n",
      "|MONTH|DAY|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_DELAY|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|result|\n",
      "+-----+---+--------------+-------------------+-------------------+---------------+-----------------+------------+-------------+--------+---------+----------------+--------------+-------------+-------------------+-------------+------+\n",
      "|    1|  1|           ANC|                SEA|               0005|            -11|             0430|        0408|          -22|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           LAX|                PBI|               0010|             -8|             0750|        0741|           -9|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           SFO|                CLT|               0020|             -2|             0806|        0811|            5|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           LAX|                MIA|               0020|             -5|             0805|        0756|           -9|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           SEA|                ANC|               0025|             -1|             0320|        0259|          -21|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           SFO|                MSP|               0025|             -5|             0602|        0610|            8|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           LAS|                MSP|               0025|             -6|             0526|        0509|          -17|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           LAX|                CLT|               0030|             14|             0803|        0753|          -10|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           SFO|                DFW|               0030|            -11|             0545|        0532|          -13|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           LAS|                ATL|               0030|              3|             0711|        0656|          -15|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           DEN|                ATL|               0030|             -6|             0523|        0453|          -30|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           LAS|                MIA|               0035|             -8|             0803|        0753|          -10|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           LAX|                MSP|               0035|              0|             0609|        0605|           -4|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           SLC|                ATL|               0040|             -6|             0615|        0553|          -22|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           SEA|                MSP|               0040|             -1|             0549|        0557|            8|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           ANC|                SEA|               0045|             -4|             0509|        0455|          -14|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           ANC|                SEA|               0045|            -14|             0515|        0451|          -24|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           SFO|                IAH|               0048|             -6|             0626|        0619|           -7|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           ANC|                PDX|               0050|             -4|             0525|        0507|          -18|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "|    1|  1|           PDX|                MSP|               0050|             -5|             0603|        0551|          -12|       0|        0|            null|          null|         null|               null|         null|     0|\n",
      "+-----+---+--------------+-------------------+-------------------+---------------+-----------------+------------+-------------+--------+---------+----------------+--------------+-------------+-------------------+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "flights_15_delayed = udf(lambda row: 1 if int('0' if row is None else row) > 15 else 0)\n",
    "\n",
    "flights_df = flights_df.withColumn('result', flights_15_delayed(flights_df['ARRIVAL_DELAY']))\n",
    "flights_df.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "flights_df = flights_df.drop(*['ORIGIN_AIRPORT','DESTINATION_AIRPORT','ARRIVAL_TIME','ARRIVAL_DELAY'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[MONTH: string, DAY: string, SCHEDULED_DEPARTURE: string, DEPARTURE_DELAY: string, SCHEDULED_ARRIVAL: string, DIVERTED: string, CANCELLED: string, AIR_SYSTEM_DELAY: double, SECURITY_DELAY: double, AIRLINE_DELAY: double, LATE_AIRCRAFT_DELAY: double, WEATHER_DELAY: double, result: string]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StandardScaler\n\u001B[1;32m      3\u001B[0m sc \u001B[38;5;241m=\u001B[39m StandardScaler()\n\u001B[1;32m      4\u001B[0m X \u001B[38;5;241m=\u001B[39m flights_df\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;241m*\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresult\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pyspark/mllib/__init__.py:26\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03mRDD-based machine learning APIs for Python (in maintenance mode).\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \n\u001B[1;32m     21\u001B[0m \u001B[38;5;124;03mThe `pyspark.mllib` package is in maintenance mode as of the Spark 2.0.0 release to encourage\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;124;03mmigration to the DataFrame-based APIs under the `pyspark.ml` package.\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# MLlib currently needs NumPy 1.4+, so complain if lower\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\n\u001B[1;32m     28\u001B[0m ver \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mint\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m numpy\u001B[38;5;241m.\u001B[39mversion\u001B[38;5;241m.\u001B[39mversion\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)[:\u001B[38;5;241m2\u001B[39m]]\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ver \u001B[38;5;241m<\u001B[39m [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m4\u001B[39m]:\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.feature import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = flights_df.drop(*['result'])\n",
    "Y = flights_df['result']\n",
    "X = sc.fit(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf.score(X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_param = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(30, 31, 1),\n",
    "    'min_samples_leaf': range(35, 38, 1),\n",
    "    'min_samples_split': range(35, 38, 1),\n",
    "    'splitter': ['best', 'random']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf,\n",
    "                           param_grid=grid_param,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion = 'entropy', max_depth=30, min_samples_leaf=35, min_samples_split=35, splitter='best')\n",
    "clf.fit(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf.score(X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "prediction = loaded_model.predict([[1,1,5,-11,430,0,0,13,0,18,22,3]])\n",
    "print(prediction)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
